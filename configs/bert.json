{
    "model_args": {
        "attention_probs_dropout_prob": 0.1,
        "hidden_act": "gelu_new",
        "hidden_dropout_prob": 0.1,
        "hidden_size": 768,
        "initializer_range": 0.02,
        "intermediate_size": 3072,
        "layer_norm_eps": 1e-12,
        "max_position_embeddings": 128,
        "num_attention_heads": 12,
        "num_hidden_layers": 12,
        "position_embedding_type": "absolute",
        "type_vocab_size": 2,
        "vocab_size": 32768
    },
    "training_args": {
        "output_dir": "out",
        "dataloader_num_workers": 0,
        "optim": "adamw_torch",
        "learning_rate": 1e-4,
        "num_train_epochs": 30,
        "per_device_train_batch_size": 64,
        "per_device_eval_batch_size": 64,
        "gradient_accumulation_steps": 2,
        "warmup_steps": 2000,
        "evaluation_strategy": "epoch",
        "save_strategy": "epoch",
        "weight_decay": 0.01,
        "logging_dir": "logs",
        "logging_steps": 100,
        "overwrite_output_dir": false,
        "save_total_limit": 2,
        "load_best_model_at_end": true,
        "prediction_loss_only": true,
        "bf16": true,
        "torch_compile": false,
        "run_name": "bert"
    },
    "dataset": "mcgill-babylm/babylm_10M",
    "tokenizer": "mcgill-babylm/tokenizer_bert-base-uncased_32768vocab_10M",
    "group_texts": false,
    "add_pos_tags": false,
    "mlm_prob": 0.15,
    "num_workers": 1,
    "cache_dir": "cache"
}